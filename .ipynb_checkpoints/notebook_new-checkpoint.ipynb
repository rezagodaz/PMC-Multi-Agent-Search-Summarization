{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4514072b-ff87-46f3-baa4-62f12fc6a612",
   "metadata": {},
   "source": [
    "# PMC Multi-Agent Search & Summarization — notebook.ipynb\n",
    "\n",
    "This document contains a runnable notebook-style guide (sections + code snippets) and a README for the Sanofi R&D case study. It's intended to be copy-pasted into a Jupyter notebook (or run cell-by-cell).\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "Setup & data access\n",
    "\n",
    "Retriever Agent\n",
    "\n",
    "Summarizer Agent\n",
    "\n",
    "(Optional) Verifier Agent\n",
    "\n",
    "Report generation\n",
    "\n",
    "README (run instructions, design choices)\n",
    "\n",
    "## 1. Setup & data access\n",
    "\n",
    "Goal: work with a small subset (<100) of PMC OA oa_comm full-text .txt files located in the public S3 bucket pmc-oa-opendata in us-east-1.\n",
    "\n",
    "Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f1ced-afd6-4f71-bcf6-37695df38b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m venv pmc_agent\n",
    "source pmc_agent/bin/activate\n",
    "pip install --upgrade pip\n",
    "pip install pandas botocore sentence-transformers transformers torch scikit-learn faiss-cpu jupyterlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4fb8a5-bb79-4f1a-9cea-1cdfeca90d0c",
   "metadata": {},
   "source": [
    "## Access S3 (no AWS credentials required)\n",
    "\n",
    "You can list/copy files directly via AWS CLI without credentials using --no-sign-request with an unsigned config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689b1de-4b8f-4158-922c-9570b843e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list top-level\n",
    "aws s3 ls --no-sign-request s3://pmc-oa-opendata/oa_comm/ | head\n",
    "\n",
    "# fetch the CSV filelist (metadata)\n",
    "aws s3 cp --no-sign-request s3://pmc-oa-opendata/oa_comm/txt/metadata/csv/oa_comm.filelist.csv ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2129d70-d10f-44b7-93fa-346f62a25c9b",
   "metadata": {},
   "source": [
    "## 2. Retriever Agent\n",
    "\n",
    "### Design:\n",
    "The Retriever Agent is responsible for fetching biomedical documents that are most relevant to a user’s query. It does this by embedding abstracts into a vector space, comparing them to the embedded query, and ranking results by semantic similarity. Unlike summarization, this agent’s job is only to retrieve and present relevant abstracts.\n",
    "\n",
    "Model (CPU-friendly):\n",
    "sentence-transformers/all-MiniLM-L6-v2 — produces 384-dimensional embeddings quickly and efficiently.\n",
    "\n",
    "### Steps & Code:\n",
    "\n",
    "#### Corpus Preparation\n",
    "\n",
    "For each PMID from the metadata file (oa_comm.filelist.csv), download the corresponding full-text .txt document from S3 (oa_comm/txt/all/{PMID}.txt).\n",
    "\n",
    "Extract the title and abstract (fallback to first ~300 words if abstract is missing).\n",
    "\n",
    "Store results in a document table (PMID, title, abstract, text).\n",
    "\n",
    "#### Embedding Index\n",
    "\n",
    "Encode all abstracts with SentenceTransformer.\n",
    "\n",
    "Store embeddings in a NumPy array for fast similarity search.\n",
    "\n",
    "#### Retrieval Function\n",
    "\n",
    "Encodes the query.\n",
    "\n",
    "Computes cosine similarity against stored embeddings.\n",
    "\n",
    "Returns the top-k documents ranked by relevance score.\n",
    "\n",
    "Agent Integration (Reasoning + Action)\n",
    "\n",
    "Uses GPT-4o-mini to decide whether retrieval is needed.\n",
    "\n",
    "If yes, GPT calls the retrieve_tool.\n",
    "\n",
    "#### The agent records:\n",
    "\n",
    "Reasoning (Thought): e.g., “I need to retrieve documents for this biomedical query.”\n",
    "\n",
    "Action: invocation of the retrieve_tool.\n",
    "\n",
    "Observation: number of documents retrieved.\n",
    "\n",
    "Output: retrieved documents (PMID, title, abstract, score).\n",
    "\n",
    "#### Example wrapper:\n",
    "\n",
    "retriever_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"retrieve_tool\",\n",
    "            \"description\": \"Retrieve relevant biomedical papers for a given query (without summarization).\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\"},\n",
    "                    \"top_k\": {\"type\": \"integer\", \"default\": 5},\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "#### Execution \n",
    "\n",
    "🤔 Thought: I need to retrieve documents.\n",
    "🔎 Action: retrieve_tool(query=\"Adverse events with mRNA vaccines in pediatrics\", top_k=5)\n",
    "📄 Observation: Retrieved 5 documents.\n",
    "\n",
    "\n",
    "Output: list of abstracts and metadata, ready for downstream processing (e.g., summarizer agent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41b426e1-42aa-431b-ab04-2d004b9e24fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scores: [ 0.16886362  0.18520235 -0.04030042  0.07915587  0.07436326  0.04194159\n",
      "  0.01086882 -0.06934417  0.29671973  0.02270352 -0.00646156  0.14045893\n",
      "  0.11386014  0.04435049  0.03969971 -0.00755932  0.11347413 -0.00453467\n",
      "  0.21948662  0.10990962 -0.05809837 -0.03347653 -0.10428705  0.04117587\n",
      "  0.16852488  0.00554047  0.12521012  0.23691656  0.21472375  0.07521107\n",
      "  0.00839179 -0.0390802   0.11271232  0.10027247  0.10864428  0.14425398\n",
      " -0.01665949 -0.11803625  0.08784895 -0.00330128  0.05201231  0.18813506\n",
      "  0.02010169  0.02175671  0.00740073 -0.08665704  0.04330515  0.17324978\n",
      " -0.1061269   0.07157484]\n",
      "The Retriever Agent Results: 🤔 Thought: I need to retrieve documents for this query.\n",
      "🔎 Action: retrieve_tool(query=adverse effects of mRNA vaccines in children, top_k=5)\n",
      "📄 Observation: Retrieved 5 documents.\n",
      "💡 Final Answer: Reports on adverse effects of mRNA vaccines in children have indicated a range of potential reactions. Most commonly, these are similar to those observed in adults, but it is essential to note that severe adverse effects are rare. Here are some notable points regarding the adverse effects reported:\n",
      "\n",
      "1. **Common Side Effects**:\n",
      "   - **Local Reactions**: Pain at the injection site, redness, and swelling.\n",
      "   - **Systemic Reactions**: Fatigue, headache, chills, fever, and muscle aches. These effects are often indicative of the immune response and typically resolve within a few days.\n",
      "\n",
      "2. **Myocarditis and Pericarditis**:\n",
      "   - There have been reports of increased cases of myocarditis and pericarditis, especially following the second dose of mRNA vaccines (e.g., Pfizer-BioNTech and Moderna) in adolescents and young adults, primarily males. Although these cases are rare, they can lead to serious health issues and require monitoring.\n",
      "\n",
      "3. **Allergic Reactions**:\n",
      "   - Some cases of severe allergic reactions (anaphylaxis) have been reported, although these are very rare. Observing individuals for a brief period after vaccination can help manage any immediate reactions.\n",
      "\n",
      "4. **Other Rare Events**:\n",
      "   - Some other neurological or immunological issues have been reported, but these occurrences remain infrequent, and their connection to the vaccine needs further study.\n",
      "\n",
      "5. **Long-term Safety**:\n",
      "   - Ongoing monitoring continues, as long-term safety data are essential in the pediatric population. \n",
      "\n",
      "6. **Official Recommendations**:\n",
      "   - Health authorities, including the CDC and WHO, continue to emphasize that the benefits of vaccination in preventing COVID-19 and its complications outweigh the risks of these potential adverse effects.\n",
      "\n",
      "The data surrounding mRNA vaccine safety, especially in children, is actively collected and analyzed through various platforms, ensuring that any new findings are quickly addressed and communicated. Parents should consult healthcare providers for the most current and personalized advice regarding COVID-19 vaccination for children.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Data Ingestion\n",
    "# ------------------------------\n",
    "\n",
    "# Load metadata (CSV from PMC Open Access)\n",
    "filelist = pd.read_csv(\"..//oa_comm.filelist.csv\")\n",
    "sample_pmids = filelist[\"AccessionID\"].sample(50, random_state=42).tolist()\n",
    "\n",
    "# Configure unsigned S3 client for public PMC bucket\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    config=Config(signature_version=UNSIGNED),\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "def download_document(pmid: str) -> str:\n",
    "    \"\"\"Download a full-text document from PMC Open Access.\"\"\"\n",
    "    key = f\"oa_comm/txt/all/{pmid}.txt\"\n",
    "    obj = s3.get_object(Bucket=\"pmc-oa-opendata\", Key=key)\n",
    "    #return obj[\"Body\"].read().decode(\"utf-8\")\n",
    "    return obj[\"Body\"].read().decode(\"latin-1\")\n",
    "\n",
    "\n",
    "def extract_metadata(text: str) -> tuple[str, str]:\n",
    "    \"\"\"Extract title and abstract from the raw document.\"\"\"\n",
    "    lines = text.splitlines()\n",
    "    title, abstract = \"\", \"\"\n",
    "    for line in lines:\n",
    "        if line.lower().startswith(\"title:\"):\n",
    "            title = line[len(\"title:\"):].strip()\n",
    "        if line.lower().startswith(\"abstract:\"):\n",
    "            abstract = line[len(\"abstract:\"):].strip()\n",
    "    if not abstract:  # fallback: first ~300 words\n",
    "        abstract = \" \".join(lines[:50])\n",
    "    return title, abstract\n",
    "\n",
    "# Prepare corpus\n",
    "documents = []\n",
    "for pmid in sample_pmids:\n",
    "    text = download_document(pmid)\n",
    "    title, abstract = extract_metadata(text)\n",
    "    documents.append({\n",
    "        \"pmid\": pmid,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"text\": text\n",
    "    })\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Embedding Model\n",
    "# ------------------------------\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_texts = [d[\"abstract\"] or d[\"text\"][:1000] for d in documents]\n",
    "doc_embeddings = model.encode(doc_texts, show_progress_bar=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Retriever\n",
    "# ------------------------------\n",
    "\n",
    "def retrieve(query: str, top_k: int = 5):\n",
    "    \"\"\"Retrieve top-k most relevant documents for a given query.\"\"\"\n",
    "    query_emb = model.encode([query])\n",
    "    scores = cosine_similarity(query_emb, doc_embeddings)[0]\n",
    "    print(\" Scores:\", scores)  # Debug: print similarity scores\n",
    "    \n",
    "    indices = np.argsort(scores)[::-1][:top_k]\n",
    "    return [\n",
    "        {\n",
    "            \"pmid\": documents[i][\"pmid\"],\n",
    "            \"title\": documents[i][\"title\"],\n",
    "            \"abstract\": documents[i][\"abstract\"],\n",
    "            \"relevance_score\": float(scores[i]),\n",
    "        }\n",
    "        for i in indices\n",
    "    ]\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Agent Integration\n",
    "# ------------------------------\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "OPEN_AI_KEY=os.getenv('OPEN_AI_KEY')\n",
    "client = OpenAI(api_key=OPEN_AI_KEY)\n",
    "\n",
    "def retrieve_tool(query: str, top_k: int = 5):\n",
    "    \"\"\"Tool wrapper for the retriever.\"\"\"\n",
    "    return retrieve(query, top_k=top_k)\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"retrieve_tool\",\n",
    "            \"description\": \"Retrieve relevant biomedical papers for a given query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\", \"description\": \"The research query to retrieve documents for\"},\n",
    "                    \"top_k\": {\"type\": \"integer\", \"default\": 5},\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "def run_agent(query: str, show_trace: bool = True):\n",
    "    \"\"\"\n",
    "    Run the agent with explicit reasoning (thought),\n",
    "    action (tool use), observation (retrieved results),\n",
    "    and final answer synthesis.\n",
    "    \"\"\"\n",
    "    trace = []\n",
    "\n",
    "    # Step 1: Ask GPT if retrieval is needed\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a biomedical research assistant. Use tools if needed before answering.\"},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "\n",
    "    # Step 2: If GPT calls the retriever tool\n",
    "    if message.tool_calls:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        if show_trace:\n",
    "            trace.append(f\"🤔 Thought: I need to retrieve documents for this query.\")\n",
    "            trace.append(f\"🔎 Action: retrieve_tool(query={args['query']}, top_k={args.get('top_k', 5)})\")\n",
    "\n",
    "        retrieved_docs = retrieve_tool(**args)\n",
    "\n",
    "        if show_trace:\n",
    "            trace.append(f\"📄 Observation: Retrieved {len(retrieved_docs)} documents.\")\n",
    "\n",
    "        # Step 3: Feed results back into GPT for synthesis\n",
    "        followup = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": query},\n",
    "                {\"role\": \"assistant\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(retrieved_docs, indent=2)},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        final_answer = followup.choices[0].message.content\n",
    "        if show_trace:\n",
    "            trace.append(f\"💡 Final Answer: {final_answer}\")\n",
    "\n",
    "    else:\n",
    "        # If GPT answers directly without retrieval\n",
    "        final_answer = message.content\n",
    "        if show_trace:\n",
    "            trace.append(\"🤔 Thought: No retrieval needed.\")\n",
    "            trace.append(f\"💡 Final Answer: {final_answer}\")\n",
    "\n",
    "    return \"\\n\".join(trace) if show_trace else final_answer\n",
    "\n",
    "user_query = \"What adverse effects of mRNA vaccines have been reported in children?\"\n",
    "result = run_agent(user_query, show_trace=True)\n",
    "print(f\"The Retriever Agent Results: {result}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Example Usage\n",
    "# ------------------------------\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     user_query = \"What adverse effects of mRNA vaccines have been reported in children?\"\n",
    "#     result = run_agent(user_query, show_trace=True)\n",
    "#     print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aabf02e-5034-4acf-b5bd-38477c2de5f7",
   "metadata": {},
   "source": [
    "## 3. Summarizer Agent\n",
    "\n",
    "### Design:\n",
    "The Summarizer Agent receives the retrieved abstracts from the Retriever Agent and produces concise summaries along with key terms. Its responsibilities are:\n",
    "\n",
    "Summarization: Convert each abstract into a 2–3 sentence concise summary.\n",
    "\n",
    "Keyword Extraction: Identify top keywords in the abstract for quick reference.\n",
    "\n",
    "Unlike the Retriever Agent, this agent does not fetch documents — it operates only on already retrieved content.\n",
    "\n",
    "### Model Choices (CPU-friendly):\n",
    "\n",
    "google/flan-t5-small (used in the code)\n",
    "\n",
    "Alternatives: t5-small, facebook/bart-base\n",
    "\n",
    "### Implementation Approach:\n",
    "\n",
    "Summarization Pipeline:\n",
    "\n",
    "Use transformers.pipeline(\"summarization\") for easy abstraction.\n",
    "\n",
    "Guard against very short texts by returning them unchanged.\n",
    "\n",
    "### Keyword Extraction (TF-IDF):\n",
    "\n",
    "Build TF-IDF vectorizer over all document abstracts.\n",
    "\n",
    "Extract top-k keywords for each abstract.\n",
    "\n",
    "### Agent Tool Function:\n",
    "\n",
    "Combines summarization and keyword extraction into a single callable tool.\n",
    "\n",
    "### Agent Integration (Reasoning + Action + Observation):\n",
    "\n",
    "Reasoning (Thought): Decide that retrieved documents need summarization.\n",
    "\n",
    "Action: Call summarizer_tool on the retrieved documents.\n",
    "\n",
    "Observation: Record the number of documents summarized and preview summaries & keywords.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "Retriever → Summarizer Pipeline: The summarizer agent always operates on documents retrieved by the retriever agent.\n",
    "\n",
    "Reasoning + Action + Observation: The agent explicitly tracks the steps of deciding to summarize, performing the summarization, and observing results.\n",
    "\n",
    "Output: Returns both a trace of reasoning steps and a structured summary + keywords per document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2018ac-87a7-4bb0-bc42-53511cf03ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of summarization:  🤔 Thought: I should summarize relevant documents for this query.\n",
      "🔎 Action: summarizer_tool(query=Adverse events with mRNA vaccines in pediatrics, top_k=5)\n",
      "📄 Observation: Summarized 5 documents.\n",
      "💡 Final Answer: The discussion surrounding adverse events associated with mRNA vaccines in pediatric populations has gained increasing attention, particularly due to the broader rollout of COVID-19 vaccines in children. Here are some key points regarding the topic:\n",
      "\n",
      "### Safety Profile of mRNA Vaccines in Pediatrics\n",
      "\n",
      "1. **Common Adverse Events**:\n",
      "   - The most frequently reported side effects in children receiving mRNA vaccines include pain at the injection site, fatigue, headache, muscle pain, chills, fever, and nausea. These side effects are generally mild to moderate and resolve within a few days.\n",
      "\n",
      "2. **Serious Adverse Events**:\n",
      "   - While the incidence of serious adverse events is low, there have been reports of myocarditis and pericarditis, particularly in adolescent males after the second dose of an mRNA COVID-19 vaccine. These conditions are rare but have garnered significant attention and ongoing investigation.\n",
      "\n",
      "3. **Long-term Follow-up**: \n",
      "   - Studies and health organizations emphasize the importance of continuous monitoring for long-term effects. Although clinical trials and post-marketing surveillance have indicated that most adverse effects occur shortly after vaccination, the long-term safety data continue to be collected.\n",
      "\n",
      "4. **Vaccine Efficacy vs. Risks**:\n",
      "   - The benefits of vaccination, including protection against severe COVID-19 illness and hospitalization, generally outweigh the risks of potential adverse events based on current evidence.\n",
      "\n",
      "5. **Regulatory Oversight**:\n",
      "   - Regulatory agencies like the CDC and WHO continue to provide guidance and recommendations regarding the use of mRNA vaccines in children, considering emerging data and safety profiles.\n",
      "\n",
      "6. **Public Health Implications**:\n",
      "   - Vaccinating children is seen as a critical step in controlling the COVID-19 pandemic and reducing transmission rates in the broader community.\n",
      "\n",
      "7. **Informed Decision-Making**:\n",
      "   - Parents and guardians are encouraged to consult with healthcare providers to discuss the risks and benefits regarding COVID-19 vaccination for their children.\n",
      "\n",
      "### Conclusion\n",
      "Ongoing surveillance, research, and transparent communication about the efficacy and safety of mRNA vaccines in pediatric populations are crucial for public health and parental trust. Regular updates from health authorities aid in keeping the public informed of any emerging data regarding potential adverse events. It is important for health professionals and researchers to continue monitoring these vaccines as new information becomes available.\n",
      "\n",
      "\n",
      "The summarize[0]:  {'pmid': 'PMC9945218', 'title': '', 'summary': 'Copyright  2023 Cheng, Jiang, Wang, Xue, Wang and Gong http://creativecommons.org/licenses/by/4.0/', 'keywords': ['wang', '2023', 'tuberculosis', 'gong', 'xue', 'jiang'], 'relevance_score': 0.3326174020767212, 'abstract': ' ==== Front Front Immunol Front Immunol Front. Immunol. Frontiers in Immunology 1664-3224 Frontiers Media S.A.  10.3389/fimmu.2023.1154693 Immunology Correction Corrigendum: Bioinformatics analysis and consistency verification of a novel tuberculosis vaccine candidate HP13138PB Cheng Peng 1 2 â\\x80\\xa0 Jiang Fan 3 â\\x80\\xa0  Wang Guiyuan 1 4 â\\x80\\xa0 Wang Jie 1 Xue Yong 1 Wang Liang 2 * Gong Wenping 1 *  1 Tuberculosis Prevention and Control Key Laboratory/Beijing Key Laboratory of New Techniques of Tuberculosis Diagnosis and Treatment, Senior Department of Tuberculosis, The Eighth Medical Center of PLA General Hospital, Beijing, China 2 Department of Geriatrics, The Eighth Medical Center of PLA General Hospital, Beijing, China 3 The Second Brigade of Cadet, Basic Medical School, Air Force Military Medical University, Xiâ\\x80\\x99an, Shaanxi, China 4 Hebei North University, Zhangjiakou, Hebei, China Edited and Reviewed by: Filippo Castiglione, Technology Innovation Institute (TII), United Arab Emirates  *Correspondence: Wenping Gong, gwp891015@whu.edu.cn; Liang Wang, Wangl309@sina.com â\\x80\\xa0These authors have contributed equally to this work  This article was submitted to Vaccines and Molecular Therapeutics, a section of the journal Frontiers in Immunology  08 2 2023 2023 08 2 2023 14 115469331 1 2023 02 2 2023 Copyright Â© 2023 Cheng, Jiang, Wang, Wang, Xue, Wang and Gong 2023 Cheng, Jiang, Wang, Wang, Xue, Wang and Gong https://creativecommons.org/licenses/by/4.0/ This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. A Corrigendum on Bioinformatics analysis and consistency verification of a novel tuberculosis vaccine candidate HP13138PB by Cheng P, Jiang F, Wang G, Wang J, Xue Y, Wang L and Gong W (2023) Front. Immunol. 14:1102578. doi:Â\\xa010.3389/fimmu.2023.1102578 tuberculosis epitope vaccines immunoinformatics immune responses bioinformatics ==== Body pmcIn the published article, there was an error in FigureÂ\\xa02A as published. The â\\x80\\x9cH13132â\\x80\\x9d should be changed to â\\x80\\x9cHP13138PBâ\\x80\\x9d in the FigureÂ\\xa02A . The corrected FigureÂ\\xa02 and its caption â\\x80\\x9cFigureÂ\\xa02. (A) The molecular solubility of the HP13138PB vaccine was predicted by the Protein-Sol server. (B) The secondary structure of the HP13138PB vaccineâ\\x80\\x9d appear below. '}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Summarization Model\n",
    "# ------------------------------\n",
    "summarizer = pipeline(\"summarization\", model=\"google/flan-t5-small\", device=-1)\n",
    "\n",
    "def make_summary(text: str, max_new_tokens: int = 120) -> str:\n",
    "    \"\"\"Summarize a given text, skipping very short inputs.\"\"\"\n",
    "    if len(text.split()) < 30:\n",
    "        return text\n",
    "    out = summarizer(text, max_new_tokens=max_new_tokens, truncation=True)\n",
    "    return out[0][\"summary_text\"]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Keyword Extraction (TF-IDF)\n",
    "# ------------------------------\n",
    "doc_texts = [d[\"abstract\"] or d[\"text\"][:2000] for d in documents]\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=2000)\n",
    "X = vectorizer.fit_transform(doc_texts)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "def top_keywords(idx: int, k: int = 6):\n",
    "    row = X[idx].toarray()[0]\n",
    "    top_idx = np.argsort(row)[::-1][:k]\n",
    "    return [terms[i] for i in top_idx if row[i] > 0]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Summarizer Tool\n",
    "# ------------------------------\n",
    "def summarize_documents(docs, max_new_tokens=120):\n",
    "    \"\"\"Produce summaries + keywords for retrieved documents.\"\"\"\n",
    "    summaries = []\n",
    "    for doc in docs:\n",
    "        text = doc[\"abstract\"] or doc[\"text\"][:2000]\n",
    "        summary = make_summary(text, max_new_tokens=max_new_tokens)\n",
    "        kw = top_keywords(documents.index(next(d for d in documents if d[\"pmid\"] == doc[\"pmid\"])), k=6)\n",
    "        summaries.append({\n",
    "            \"pmid\": doc[\"pmid\"],\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"summary\": summary,\n",
    "            \"keywords\": kw,\n",
    "            \"relevance_score\": doc[\"relevance_score\"],\n",
    "            \"abstract\": doc[\"abstract\"]\n",
    "        })\n",
    "    return summaries\n",
    "\n",
    "\n",
    "def summarizer_tool(query: str, top_k: int = 5):\n",
    "    \"\"\"Agent tool: retrieve documents, then summarize them.\"\"\"\n",
    "    retrieved = retrieve(query, top_k=top_k)\n",
    "    return summarize_documents(retrieved)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Agent Integration\n",
    "# ------------------------------\n",
    "summarizer_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"summarizer_tool\",\n",
    "            \"description\": \"Retrieve relevant biomedical papers and summarize them with keywords.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\", \"description\": \"The research query to retrieve & summarize\"},\n",
    "                    \"top_k\": {\"type\": \"integer\", \"default\": 5},\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "def run_summarizer_agent(query: str, show_trace: bool = True):\n",
    "    \"\"\"\n",
    "    Summarizer Agent:\n",
    "    - Thought: decide if summarization is needed\n",
    "    - Action: retrieve & summarize\n",
    "    - Observation: summaries & keywords\n",
    "    - Final Answer: synthesis\n",
    "    \"\"\"\n",
    "    trace = []\n",
    "\n",
    "    # Step 1: Ask GPT whether to call summarizer_tool\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a biomedical summarization assistant. Use tools to retrieve & summarize literature if needed.\"},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        tools=summarizer_tools,\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "\n",
    "    if message.tool_calls:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        if show_trace:\n",
    "            trace.append(\"🤔 Thought: I should summarize relevant documents for this query.\")\n",
    "            trace.append(f\"🔎 Action: summarizer_tool(query={args['query']}, top_k={args.get('top_k', 5)})\")\n",
    "\n",
    "        summaries = summarizer_tool(**args)\n",
    "\n",
    "        if show_trace:\n",
    "            trace.append(f\"📄 Observation: Summarized {len(summaries)} documents.\")\n",
    "\n",
    "        followup = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": query},\n",
    "                {\"role\": \"assistant\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(summaries, indent=2)},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        final_answer = followup.choices[0].message.content\n",
    "        if show_trace:\n",
    "            trace.append(f\"💡 Final Answer: {final_answer}\")\n",
    "\n",
    "    else:\n",
    "        final_answer = message.content\n",
    "        if show_trace:\n",
    "            trace.append(\"🤔 Thought: No summarization needed.\")\n",
    "            trace.append(f\"💡 Final Answer: {final_answer}\")\n",
    "\n",
    "    return \"\\n\".join(trace) if show_trace else final_answer , summaries\n",
    "\n",
    "\n",
    "query = \"Adverse events with mRNA vaccines in pediatrics\"\n",
    "result, summaries = run_summarizer_agent(query, show_trace=True)\n",
    "print(\"The result of summarization: \",result)\n",
    "print(\"\\n\\nThe summarize[0]: \",summaries[0])\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Example Usage\n",
    "# ------------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     query = \"Adverse events with mRNA vaccines in pediatrics\"\n",
    "#     result = run_summarizer_agent(query, show_trace=True)\n",
    "#     print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec3e3e-197d-4beb-8194-0ece216a967f",
   "metadata": {},
   "source": [
    "## 4. (Optional) Verifier Agent\n",
    "\n",
    "### Design:\n",
    "The Verifier Agent ensures that the summaries produced by the Summarizer Agent are faithful, relevant, and complete with respect to the retrieved abstracts. Its responsibilities are:\n",
    "\n",
    "Verification: Compare the summary against the abstracts used for summarization.\n",
    "\n",
    "Scoring: Assign a faithfulness score and flag potential hallucinations or missing critical information.\n",
    "\n",
    "Decision-making: Provide a final verification assessment that can be used to accept, refine, or reject the summary.\n",
    "\n",
    "Unlike the Retriever or Summarizer Agents, the Verifier Agent does not fetch or summarize content, but it takes structured outputs from the previous agent.\n",
    "\n",
    "### Implementation Approach:\n",
    "\n",
    "Verification Tool:\n",
    "\n",
    "Receives the summary and the source abstracts (sources).\n",
    "\n",
    "Performs a basic verification, e.g., checks keyword overlap, length, and alignment with sources.\n",
    "\n",
    "### Verifier Agent Function:\n",
    "\n",
    "Combines reasoning, action, and observation into a single agent function.\n",
    "\n",
    "Input / Output:\n",
    "\n",
    "Input:\n",
    "\n",
    "{\n",
    "    \"query\": \"Adverse events with mRNA vaccines in pediatrics\",\n",
    "    \"summary\": \"mRNA vaccines in children mostly cause mild, short-lived adverse events, with no severe cases reported in trials.\",\n",
    "    \"abstract\": [list of retrieved abstracts used for summarization]\n",
    "}\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "{\n",
    "    \"verification\": {\"faithfulness_score\": 0.45, \"length_ok\": True, \"comment\": \"Summary aligns well with retrieved docs.\"},\n",
    "    \"final_answer\": \"...\",\n",
    "    \"trace\": [reasoning, action, observation steps]\n",
    "}\n",
    "\n",
    "\n",
    "Key Features:\n",
    "\n",
    "Reasoning: GPT (or the agent logic) decides whether verification is needed.\n",
    "\n",
    "Action: Runs the verifier_tool on the summary and sources.\n",
    "\n",
    "Observation: Records results and computes scores for faithfulness and completeness.\n",
    "\n",
    "Output: Structured feedback for downstream use, including potential refinement or acceptance of the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8fa22-fff6-438b-96f4-56a175359873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of verification:  {'verification': {'faithfulness_score': 0.0, 'length_ok': False, 'comment': 'Potential hallucination / weak grounding.'}, 'final_answer': 'Final Verification Decision: The summary provided contains a correction notice related to a scientific article, which appears to have an inconsistency regarding the figure labels. The issues flagged include a zero faithfulness score and length discrepancies, suggesting the summary may not accurately represent the original content. Furthermore, there are signs of potential hallucination or weak grounding. \\n\\nDecision: **Not Verified**.', 'trace': ['🤔 Reasoning: Checking whether to verify summarizer output.', '🔎 Action: verifier_tool(summary=..., sources=1 docs)', '📋 Observation: {\\n  \"faithfulness_score\": 0.0,\\n  \"length_ok\": false,\\n  \"comment\": \"Potential hallucination / weak grounding.\"\\n}', '✅ Final Answer: Final Verification Decision: The summary provided contains a correction notice related to a scientific article, which appears to have an inconsistency regarding the figure labels. The issues flagged include a zero faithfulness score and length discrepancies, suggesting the summary may not accurately represent the original content. Furthermore, there are signs of potential hallucination or weak grounding. \\n\\nDecision: **Not Verified**.']}\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "#from openai import OpenAI\n",
    "\n",
    "#client = OpenAI()\n",
    "\n",
    "# ---- VERIFIER TOOL ----\n",
    "def verifier_tool(summary: str, sources: list) -> dict:\n",
    "    \"\"\"\n",
    "    Verifies whether the summarizer's output is faithful and relevant.\n",
    "    - Checks alignment between the summary and provided abstracts.\n",
    "    - Detects hallucinations or missing critical points.\n",
    "    \"\"\"\n",
    "    # For now, do a simple keyword overlap + length check\n",
    "    keywords = [word.lower() for src in sources for word in src.split() if len(word) > 6]\n",
    "    summary_words = summary.lower().split()\n",
    "    overlap = len(set(summary_words) & set(keywords)) / max(1, len(set(summary_words)))\n",
    "\n",
    "    return {\n",
    "        \"faithfulness_score\": round(overlap, 3),\n",
    "        \"length_ok\": len(summary.split()) > 30,\n",
    "        \"comment\": (\n",
    "            \"Summary aligns well with retrieved docs.\"\n",
    "            if overlap > 0.2 else \"Potential hallucination / weak grounding.\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "verifier_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"verifier_tool\",\n",
    "            \"description\": \"Verify that the summary is faithful, relevant, and complete given the retrieved sources.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"summary\": {\"type\": \"string\"},\n",
    "                    \"sources\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "                },\n",
    "                \"required\": [\"summary\", \"sources\"]\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# ---- VERIFIER AGENT ----\n",
    "def run_verifier_agent(summary_results: dict):\n",
    "    \"\"\"\n",
    "    Verifier Agent: receives summarizer output (summary + sources) and verifies it.\n",
    "    \"\"\"\n",
    "    #query = summary_results[\"query\"]\n",
    "    summary = summary_results[\"summary\"]\n",
    "    sources = summary_results[\"abstract\"]\n",
    "\n",
    "    trace = []\n",
    "\n",
    "    # Step 1: Reasoning — decide if verification is needed\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a verifier agent. Your job is to decide if a summary should be verified against its sources.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Query: {query}\\nSummary: {summary}\\nSources: {len(sources)} documents\"}\n",
    "        ],\n",
    "        tools=verifier_tools,\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "    trace.append(\"🤔 Reasoning: Checking whether to verify summarizer output.\")\n",
    "\n",
    "    # Step 2: Action — if tool call is triggered, run verifier\n",
    "    if message.tool_calls:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        trace.append(f\"🔎 Action: verifier_tool(summary=..., sources={len(args['sources'])} docs)\")\n",
    "        verification = verifier_tool(**args)\n",
    "\n",
    "        # Step 3: Observation\n",
    "        trace.append(f\"📋 Observation: {json.dumps(verification, indent=2)}\")\n",
    "\n",
    "        # Step 4: Final Answer\n",
    "        followup = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a verifier agent. Provide a final verification decision.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Summary: {summary}\\nSources: {sources}\\nVerification: {verification}\"},\n",
    "            ],\n",
    "        )\n",
    "        trace.append(f\"✅ Final Answer: {followup.choices[0].message.content}\")\n",
    "        return {\"verification\": verification, \"final_answer\": followup.choices[0].message.content, \"trace\": trace}\n",
    "\n",
    "    # No tool call = GPT decided no verification needed\n",
    "    trace.append(\"⚠️ No verification needed.\")\n",
    "    return {\"verification\": None, \"final_answer\": summary, \"trace\": trace}\n",
    "\n",
    "\n",
    "result_ver = run_verifier_agent(summaries[0])\n",
    "#print(\"The result of verification: \",result_ver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
